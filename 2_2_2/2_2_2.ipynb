{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0a47ed",
   "metadata": {},
   "source": [
    "2.2 Regression - Predicting Hero win rate from Overwatch 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a3845",
   "metadata": {},
   "source": [
    "            Dataset presentation:\n",
    "\n",
    "Number of samples: 1440\n",
    "\n",
    "Number of features: 126\n",
    "\n",
    "Target variable: \"win rate, %\"\n",
    "\n",
    "Unit: Percentage (%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62827328",
   "metadata": {},
   "source": [
    "            Dataset description\n",
    "\n",
    "This dataset contains a list of performance statistics from Overwatch 2 heroes across multiple competitive seasons (Season 01 to Season 04) and Quick Play mode. \n",
    "Each row represents a hero performance snapshot at a given skill tier and season. The dataset includes detailed numerical metrics such as damage dealt, eliminations, deaths, healing, objective time, and accuracy-related statistics, as well as categorical information like hero name, role, and skill tier.\n",
    "\n",
    "Link for the dataset: \"https://www.kaggle.com/datasets/mykhailokachan/overwatch-2-statistics/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e200262",
   "metadata": {},
   "source": [
    "            Problem statement\n",
    "\n",
    "The goal of this study is to use regression model training to predict the win rate of an Overwatch 2 hero in percentage, taking features like  in-game performance statisitcs and contextual variables as role and skill tier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f44a1",
   "metadata": {},
   "source": [
    "            Data Analysis\n",
    "\n",
    "The target variable win rate shows a relatively narrow distribution, mostly between 40% and 60%, which is expected value for a balanced competitive game.\n",
    "\n",
    "Eliminations, damage dealt, and objective time are positively correlated with win rate, while deaths show a negative correlation.\n",
    "However, most correlations remain moderate, indicating that win rate depends on complex interactions between features rather than single dominant variables.\n",
    "\n",
    "Role-based analysis shows different statistical profiles: supports dominate healing metrics, damage heroes show higher variance in damage output, and tanks exhibit more stable survivability-related metrics.\n",
    "\n",
    "No extreme outliers (e.g. 0% or 100%) are observed, which confirms the dataset consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2914fe",
   "metadata": {},
   "source": [
    "            Regression models\n",
    "\n",
    "Linear Regression\n",
    "\n",
    "A baseline linear regression model is used to assess linear relationships. Performance is limited due to the complexity of the problem.\n",
    "\n",
    "Ridge and Lasso Regression\n",
    "\n",
    "Regularized linear models are trained with hyperparameters optimized via cross-validation. Ridge regression briefly improves performance over the baseline, while Lasso performs implicit feature selection.\n",
    "\n",
    "Random Forest Regressor\n",
    "\n",
    "A non-linear ensemble model is trained to catch complex interactions. Hyperparameters like as number of trees and maximum depth are optimized. This kind of model achieves the best overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adcba7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <td>2.652707</td>\n",
       "      <td>0.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>2.688208</td>\n",
       "      <td>0.661109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>2.745769</td>\n",
       "      <td>0.646440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>2.836484</td>\n",
       "      <td>0.622692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RMSE        R2\n",
       "Linear        2.652707  0.670000\n",
       "Ridge         2.688208  0.661109\n",
       "Lasso         2.745769  0.646440\n",
       "RandomForest  2.836484  0.622692"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install dependencies (separate cell ideally)\n",
    "# %pip install pandas scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# -------------------------\n",
    "# Load datasets\n",
    "# -------------------------\n",
    "paths = [\n",
    "    './dataset/data/ow2_quickplay_heroes_stats__2023-05-06.csv',\n",
    "    './dataset/data/ow2_season_01_FINAL_heroes_stats__2023-05-06.csv',\n",
    "    './dataset/data/ow2_season_02_FINAL_heroes_stats__2023-05-06.csv',\n",
    "    './dataset/data/ow2_season_03_FINAL_heroes_stats__2023-05-06.csv',\n",
    "    './dataset/data/ow2_season_04_FINAL_heroes_stats__2023-06-27.csv'\n",
    "]\n",
    "\n",
    "dfs = [pd.read_csv(p) for p in paths]\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# -------------------------\n",
    "# Define target\n",
    "# -------------------------\n",
    "target = 'Win Rate, %'\n",
    "\n",
    "data[target] = pd.to_numeric(data[target], errors='coerce')\n",
    "data = data.dropna(subset=[target]).reset_index(drop=True)\n",
    "\n",
    "y = data[target]\n",
    "X = data.drop(columns=[target])\n",
    "\n",
    "# -------------------------\n",
    "# Identify variable types\n",
    "# -------------------------\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "X[categorical_cols] = X[categorical_cols].fillna(\"UNKNOWN\").astype(str)\n",
    "\n",
    "# -------------------------\n",
    "# Preprocessing pipelines\n",
    "# -------------------------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='UNKNOWN')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Train / test split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Models\n",
    "# -------------------------\n",
    "models = {\n",
    "    'Linear': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=0.01),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# -------------------------\n",
    "# Training loop\n",
    "# -------------------------\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('preprocess', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    r2 = r2_score(y_test, preds)\n",
    "\n",
    "    results[name] = {'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "results\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee69289",
   "metadata": {},
   "source": [
    "            Evaluation metrics\n",
    "\n",
    "To evaluate the regression models, two metrics were used:\n",
    "\n",
    "RMSE (Root Mean Squared Error), which measures the average prediction error in percentage points.\n",
    "\n",
    "R² score, which indicates the proportion of variance in the target variable explained by the model.\n",
    "\n",
    "Lower RMSE values indicate better predictive accuracy, while higher R² values indicate better explanatory power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65a382f",
   "metadata": {},
   "source": [
    "            \n",
    "        Model comparison and interpretation of results\n",
    "\n",
    "The table compare the performance of four regression models: Linear Regression, Ridge, Lasso, and Random Forest.\n",
    "\n",
    "The Linear Regression model achieves the lowest RMSE (2.65) and the highest R² score (0.67) among all tested models.\n",
    "This indicates that it provides the most accurate predictions and explains approximately 67% of the variance in hero win rates.\n",
    "\n",
    "Ridge and Lasso regression show slightly worse performance, suggesting that regularization does not significantly improve the model in this context.\n",
    "The Random Forest model performs the worst, which may be due to limited data size or high noise in the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d34b38",
   "metadata": {},
   "source": [
    "            Final model selection\n",
    "\n",
    "Linear Regression was selected as the final model.\n",
    "It provides the best balance between predictive performance, simplicity, and interpretability.\n",
    "\n",
    "Additionally, linear regression is well suited for understanding the influence of individual features on the win rate, which is an important aspect of this analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2e595a",
   "metadata": {},
   "source": [
    "            Limitations of the model\n",
    "\n",
    "Despite its good performance, the model has several limitations.\n",
    "It does not account for player skill differences, team compositions, hero synergies, or balance changes between patches.\n",
    "\n",
    "Moreover, win rate is influenced by many external factors that are not present in the dataset, which explains why the R² score is not closer to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8a932d",
   "metadata": {},
   "source": [
    "            Conclusion\n",
    "\n",
    "This study shows an hero performance statistics can be used to predict win rates with reasonable accuracy.\n",
    "Among the tested models, linear regression achieved the best results, with an RMSE of approximately 2.65 and an R² score of 0.67.\n",
    "\n",
    "These results show that statistical features explain a significant portion of win rate variability, while leaving room for further improvements using additional contextual data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
